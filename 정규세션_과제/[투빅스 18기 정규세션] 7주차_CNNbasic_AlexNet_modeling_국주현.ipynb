{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1DbkY70-hcB"
      },
      "source": [
        "# CNNbasic Assignment#2\n",
        "\n",
        "# AlexNet 구현\n",
        "\n",
        "모델 구현 후 summary로 전체 모델 구조 출력과 주석으로 간단한 설명을 달아주시면 됩니다.\n",
        "\n",
        "프레임워크는 자유이고, 기본 tensforflow와 pytorch tutorial 사이트를 아래에 첨부해 드립니다.\n",
        "\n",
        "이 외 각 프레임워크 별 summary 등 추가적인 사용 방법은 구글링으로 찾아주세요!-!\n",
        "\n",
        "- Tensorflow Tutorial: https://www.tensorflow.org/tutorials?hl=ko\n",
        "\n",
        "- Pytorch Tutorial: https://tutorials.pytorch.kr/\n",
        "\n",
        "![image-2.png](attachment:image-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 논문 컨셉\n",
        "\n",
        "    논문제목은 “ImageNet Classification with Deep Convolution Neural Networks”\n",
        "\n",
        "    이미지 관련 모델로서, 2012년 ILSVRC에서 큰 격차로 1등을 기록. AlexNet은 Alex Krizhevsky라는 1저자가 논문을 써서 이름이 알렉스\n",
        "\n",
        "\n",
        "- 모델 특징\n",
        "\n",
        "    당시 주로 Activation function으로 Sigmoid, tanh를 주로 사용하던 기존 모델과 달리 AlexNet에서는 ReLU함수를 사용\n",
        "\n",
        "    ReLU의 비용이 다른 Activation Function보다 비교적 적은데, CIFAR-10을 가지고 비교한 결과 25% training error rate에 도달하는 시간이 6배 빠름\n",
        "\n",
        "\n",
        "- Local Response Normalization\n",
        "\n",
        "    ReLU는 Sigmoid형 함수와는 달리 input normalization이 필수는 아님. AlexNet에서는 local response normalization을 적용해 오차를 약 1~2% 줄였다고 밝힘\n",
        "    \n",
        "    최근에는 잘 쓰이지 않는 방법\n",
        "\n",
        "\n",
        "- Overlapping Pooling\n",
        "\n",
        "    보통 CNN같은 이미지 모델에서는 pooling unit의 크기와 stride의 크기가 같이 설정. 하지만 AlexNet에서는 Pooling unit이 더큰 Overlapping Pooling기법을 사용하여 0.4% 오차감소를 얻음.\n",
        "\n",
        "\n",
        "- Data Augmentation\n",
        "\n",
        "    “이미지-라벨”이라는 1가지 학습데이터로 이미지에 다양한 변화(사진 뒤집기, 사진 각도 전환 등등…)을 줘서 다양한 데이터셋을 생성하는 방법. 과적합 해소를 위한 방법.\n",
        "    논문에서는 두가지 방법을 이용하여 변형을 적용\n",
        "\n",
        "    1) 원본을 먼저 자른 이후 이미지를 반전 시킴\n",
        "\n",
        "    2) PCA를 통해 RGB값을 변형함\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Dropout\n",
        "\n",
        "    히든 레이어의 특정 뉴런의 출력을 일정 확률로 0으로 만드는것을 의미. 이는 뉴런들의 co-adaption을 줄인다. 즉, 불확실성을 부여해 특정 뉴런에 의존하지 못하도록 하는것. 이 또한 과적합 해소를 위한 방법"
      ],
      "metadata": {
        "id": "qjGwQgsVIDYe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yGHLrFU8JkW"
      },
      "source": [
        "## Tensorflow(keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68kj2zUP80f0",
        "outputId": "17587be5-b9d6-4718-a636-d73c45a89451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 27, 27, 96)       384       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 27, 27, 256)       614656    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 13, 13, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 13, 13, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 13, 13, 384)       885120    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 13, 13, 256)       884992    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              37752832  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,379,752\n",
            "Trainable params: 62,379,048\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "n_classes = 1000 # class 개수\n",
        "input_shape = (227, 227, 3) #이미지 인풋사이즈(227인이유: 레이어 거칠때 정수로 맞춰주려고)\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "############## Add Layer ##############\n",
        "\n",
        "# Conv1\n",
        "model.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), padding='valid', activation='relu', input_shape=input_shape))  #\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2))) #풀링\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Conv2\n",
        "model.add(Conv2D(256, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu')) \n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))#풀링\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Conv3\n",
        "model.add(Conv2D(384, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')) \n",
        "\n",
        "# Conv4\n",
        "model.add(Conv2D(384, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "\n",
        "# Conv5\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))#풀링\n",
        "\n",
        "# FC1\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "\n",
        "# FC2\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "\n",
        "# Output_layer\n",
        "model.add(Dense(n_classes, activation='softmax')) #아웃풋 : 소프트맥스를 통해 1000개의 클래스 확률값 예측\n",
        "\n",
        "#######################################\n",
        "\n",
        "# keras summary\n",
        "model.summary() # #sumary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urleB2cT-c0i"
      },
      "source": [
        "## Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPXCVbu799Rq",
        "outputId": "b4e627ed-c659-4aa2-c4c1-99628ab5ff32",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
            "              ReLU-2           [-1, 96, 55, 55]               0\n",
            "         MaxPool2d-3           [-1, 96, 27, 27]               0\n",
            "       BatchNorm2d-4           [-1, 96, 27, 27]             192\n",
            "            Conv2d-5          [-1, 256, 27, 27]         614,656\n",
            "              ReLU-6          [-1, 256, 27, 27]               0\n",
            "         MaxPool2d-7          [-1, 256, 13, 13]               0\n",
            "       BatchNorm2d-8          [-1, 256, 13, 13]             512\n",
            "            Conv2d-9          [-1, 384, 13, 13]         885,120\n",
            "             ReLU-10          [-1, 384, 13, 13]               0\n",
            "           Conv2d-11          [-1, 384, 13, 13]       1,327,488\n",
            "             ReLU-12          [-1, 384, 13, 13]               0\n",
            "           Conv2d-13          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-14          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-15            [-1, 256, 6, 6]               0\n",
            "          Flatten-16                 [-1, 9216]               0\n",
            "          Dropout-17                 [-1, 9216]               0\n",
            "           Linear-18                 [-1, 4096]      37,752,832\n",
            "             ReLU-19                 [-1, 4096]               0\n",
            "          Dropout-20                 [-1, 4096]               0\n",
            "           Linear-21                 [-1, 4096]      16,781,312\n",
            "             ReLU-22                 [-1, 4096]               0\n",
            "           Linear-23                 [-1, 1000]       4,097,000\n",
            "================================================================\n",
            "Total params: 62,379,048\n",
            "Trainable params: 62,379,048\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 12.02\n",
            "Params size (MB): 237.96\n",
            "Estimated Total Size (MB): 250.57\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:83: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes = 1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        \n",
        "        ############## Add Layer ##############\n",
        "\n",
        "        # Conv1\n",
        "        self.Conv_1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = 3, out_channels = 96, kernel_size = 11, stride = 4, padding = 0),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size = 3, stride = 2),\n",
        "          nn.BatchNorm2d(96))\n",
        "        \n",
        "        # Conv2\n",
        "        self.Conv_2 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = 96, out_channels = 256, kernel_size = 5, stride = 1, padding = 2),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size = 3, stride = 2),\n",
        "          nn.BatchNorm2d(256))\n",
        "        \n",
        "        # Conv3\n",
        "        self.Conv_3 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = 256, out_channels = 384, kernel_size = 3, stride = 1, padding = 1),\n",
        "          nn.ReLU())\n",
        "        \n",
        "        # Conv4\n",
        "        self.Conv_4 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = 384, out_channels = 384, kernel_size = 3, stride = 1, padding = 1),\n",
        "          nn.ReLU())\n",
        "        \n",
        "        # Conv5\n",
        "        self.Conv_5 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = 384, out_channels = 256, kernel_size = 3, stride = 1, padding = 1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        \n",
        "        # FC1\n",
        "        self.FC1 = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Dropout(0.5),\n",
        "          nn.Linear(9216, 4096),\n",
        "          nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # FC2\n",
        "        self.FC2 = nn.Sequential(\n",
        "          nn.Dropout(0.5),\n",
        "          nn.Linear(4096, 4096),\n",
        "          nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Output_layer\n",
        "        self.Output_layer = nn.Sequential(\n",
        "          nn.Linear(4096, n_classes)\n",
        "        )\n",
        "    \n",
        "        #######################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        ############## Add Layer ##############\n",
        "        out = self.Conv_1(x)\n",
        "        out = self.Conv_2(out)\n",
        "        out = self.Conv_3(out)\n",
        "        out = self.Conv_4(out)\n",
        "        out = self.Conv_5(out)\n",
        "        out = self.FC1(out)\n",
        "        out = self.FC2(out)\n",
        "        out = self.Output_layer(out)\n",
        "    \n",
        "        #######################################\n",
        "        \n",
        "        return F.log_softmax(out)\n",
        "\n",
        "\n",
        "# pytorch summary\n",
        "summary(AlexNet(n_classes = 1000), (3, 227, 227)) # summary code 추가"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}